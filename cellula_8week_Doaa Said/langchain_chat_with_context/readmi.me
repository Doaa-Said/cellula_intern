ğŸ§  LangChain Ollama Context-Aware Agent

A Python-based AI assistant built with LangChain, Ollama, and custom tools that provides answers with context-awareness. The agent integrates multiple tools for better reasoning and relevance, and exposes a Gradio-based user interface for interaction.

ğŸš€ Features

Context-aware answering: Uses ContextPresenceJudge and ContextRelevanceChecker to determine if provided context is sufficient.

Automatic context splitting: Uses ContextSplitter to parse and structure input context efficiently.

Web search integration: Uses a Wikipedia-based WebSearchTool to fetch information dynamically when context is insufficient.

Agent orchestration: Combines multiple tools via a LangChain agent.

Gradio UI: Easy-to-use chat interface with optional streaming support.

Streaming / non-streaming support: Answers can be generated in full or streamed in chunks for real-time updates.

ğŸ“¦ Project Structure
project/
â”‚
â”œâ”€ Agent/
â”‚   â””â”€ agent_runner.py          # Function to build agent with LLM and tools
â”‚
â”œâ”€ tools/
â”‚   â”œâ”€ context_presence_judge.py
â”‚   â”œâ”€ context_relevance_checker.py
â”‚   â”œâ”€ context_splitter.py
â”‚   â””â”€ web_search_tool.py
â”‚
â”œâ”€ ui.py                        # Main Gradio interface script
â”œâ”€ README.md
â””â”€ requirements.txt

âš™ï¸ Installation

Clone the repository

git clone https://github.com/yourusername/langchain-ollama-agent.git
cd langchain-ollama-agent


Create a virtual environment (optional but recommended)

python -m venv venv
source venv/bin/activate  # Linux / macOS
venv\Scripts\activate     # Windows


Install dependencies

pip install -r requirements.txt


Run a local Ollama model server (if using Ollama locally)

ollama serve --model llama3.2

ğŸ–¥ï¸ Usage
Run the Agent (Non-Streaming Mode)
python ui.py


Open the Gradio interface in your browser (usually at http://localhost:7860)

Type a question and optionally provide context

Get answers generated by the agent using all available tools

Example Questions

"Tell me everything about the microcontroller architecture of the TM4C123GH6PM"

"Which register is used to configure alternate functions for TM4C123GH6PM GPIO pins?"

"What is the latest news about artificial intelligence?"

ğŸ› ï¸ Tools Implemented
Tool Name	Purpose
ContextPresenceJudge	Determines if enough context is provided
ContextRelevanceChecker	Checks whether provided context is relevant to the question
ContextSplitter	Splits large context into manageable chunks
WebSearchTool	Queries Wikipedia for missing information
ğŸ“„ Example Code Snippet
from Agent.agent_runner import build_agent
from tools.context_presence_judge import build_context_presence_tool
from langchain_ollama import ChatOllama

llm = ChatOllama(model="llama3.2")
context_tool = build_context_presence_tool(llm)
agent = build_agent(llm, tools=[context_tool])

response = agent.invoke({"input": "Tell me about TM4C123GH6PM GPIOs"})
print(response)

âš¡ Future Improvements

Enable streaming output for real-time responses.

Add additional tools (e.g., documentation search, PDFs).

Integrate more powerful LLMs or multiple models.

Deploy to Hugging Face Spaces for public access.

Logging and debugging improvements for better traceability.

ğŸ“š References

LangChain Documentation

Ollama

TM4C123GH6PM Datasheet

Gradio Documentation

ğŸ“ License

MIT License â€” feel free to use, modify, and distribute.
