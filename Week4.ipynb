{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "460c71379a3f4f05a005c8ff87dcfcae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a057c1f742d1400abf34c71ed6be662e",
              "IPY_MODEL_34a851ac9ec44948b91b3bed27f02240",
              "IPY_MODEL_2e7025bc489d4fcca51cf7d51c5f1644"
            ],
            "layout": "IPY_MODEL_d97594733ab44ae4b3064aba661e3e19"
          }
        },
        "a057c1f742d1400abf34c71ed6be662e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ba1faad5dcb4e9da4b4add4fd61af2e",
            "placeholder": "​",
            "style": "IPY_MODEL_9397ee3657ee414b8c9e2f9fb34dd308",
            "value": "README.md: "
          }
        },
        "34a851ac9ec44948b91b3bed27f02240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_553edd83e0cd4b7a88ca26a31e8baa3b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_421142aa627043febfe8cdfeb17ee70e",
            "value": 1
          }
        },
        "2e7025bc489d4fcca51cf7d51c5f1644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1300e547e6004074925fa198e9b33398",
            "placeholder": "​",
            "style": "IPY_MODEL_776f52dff4e04b27a2689206ac4f9206",
            "value": " 6.52k/? [00:00&lt;00:00, 449kB/s]"
          }
        },
        "d97594733ab44ae4b3064aba661e3e19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba1faad5dcb4e9da4b4add4fd61af2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9397ee3657ee414b8c9e2f9fb34dd308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "553edd83e0cd4b7a88ca26a31e8baa3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "421142aa627043febfe8cdfeb17ee70e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1300e547e6004074925fa198e9b33398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "776f52dff4e04b27a2689206ac4f9206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aa06ef434684800be06099b13f024ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bb15393766147a29d3ea8043ceb99d2",
              "IPY_MODEL_fa6bcede46c84149a48048e8cec506db",
              "IPY_MODEL_5376fdccd754479b9a3c5eb4b7a39404"
            ],
            "layout": "IPY_MODEL_3e39b335fbd84d05b46b7ebc15383eea"
          }
        },
        "7bb15393766147a29d3ea8043ceb99d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eafcc322eaac44ecafaad71b5844715f",
            "placeholder": "​",
            "style": "IPY_MODEL_3e1a80a1d5674501b260f5c21b6cfcf4",
            "value": "openai_humaneval/test-00000-of-00001.par(…): 100%"
          }
        },
        "fa6bcede46c84149a48048e8cec506db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e9d7db1ce03402ea662cae70c71b120",
            "max": 83920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_278ecd82c3da450a872fda47d3f87ba3",
            "value": 83920
          }
        },
        "5376fdccd754479b9a3c5eb4b7a39404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c638099403644129e52c63690348c94",
            "placeholder": "​",
            "style": "IPY_MODEL_2aebf1e1e2454d3486462b7bb5bdb576",
            "value": " 83.9k/83.9k [00:00&lt;00:00, 673kB/s]"
          }
        },
        "3e39b335fbd84d05b46b7ebc15383eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eafcc322eaac44ecafaad71b5844715f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e1a80a1d5674501b260f5c21b6cfcf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e9d7db1ce03402ea662cae70c71b120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "278ecd82c3da450a872fda47d3f87ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c638099403644129e52c63690348c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aebf1e1e2454d3486462b7bb5bdb576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75741772809345d2b418330f5d51d094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a04d69e31d2f4d81bb18b4a9bd203fa8",
              "IPY_MODEL_61fc8b67071f4ceabac8e96de6f237a3",
              "IPY_MODEL_f6181f9756994eaf885da33fb4203ec6"
            ],
            "layout": "IPY_MODEL_5cb2863fdd744cf8b12dd5c5eba5d955"
          }
        },
        "a04d69e31d2f4d81bb18b4a9bd203fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec3b01d4ec61409a9b9c0c043f396fb5",
            "placeholder": "​",
            "style": "IPY_MODEL_0ac3feb7889a41cca4220c828d73c299",
            "value": "Generating test split: 100%"
          }
        },
        "61fc8b67071f4ceabac8e96de6f237a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c16bb6a583a4496bf9acd9574590553",
            "max": 164,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76f11bdeda7840dfaa8eeb04196d79ac",
            "value": 164
          }
        },
        "f6181f9756994eaf885da33fb4203ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81ad769829c046b6a1932ec11f48ceb3",
            "placeholder": "​",
            "style": "IPY_MODEL_04655bb193fd4a229c4d94f4ec7709e2",
            "value": " 164/164 [00:00&lt;00:00, 2336.64 examples/s]"
          }
        },
        "5cb2863fdd744cf8b12dd5c5eba5d955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec3b01d4ec61409a9b9c0c043f396fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac3feb7889a41cca4220c828d73c299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c16bb6a583a4496bf9acd9574590553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f11bdeda7840dfaa8eeb04196d79ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81ad769829c046b6a1932ec11f48ceb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04655bb193fd4a229c4d94f4ec7709e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUzHtD4_KbV7",
        "outputId": "90ccfa1c-16f6-4caf-b736-fc87f4490767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Salesforce/codegen-350M-mono were not used when initializing CodeGenForCausalLM: ['transformer.h.0.attn.causal_mask', 'transformer.h.1.attn.causal_mask', 'transformer.h.10.attn.causal_mask', 'transformer.h.11.attn.causal_mask', 'transformer.h.12.attn.causal_mask', 'transformer.h.13.attn.causal_mask', 'transformer.h.14.attn.causal_mask', 'transformer.h.15.attn.causal_mask', 'transformer.h.16.attn.causal_mask', 'transformer.h.17.attn.causal_mask', 'transformer.h.18.attn.causal_mask', 'transformer.h.19.attn.causal_mask', 'transformer.h.2.attn.causal_mask', 'transformer.h.3.attn.causal_mask', 'transformer.h.4.attn.causal_mask', 'transformer.h.5.attn.causal_mask', 'transformer.h.6.attn.causal_mask', 'transformer.h.7.attn.causal_mask', 'transformer.h.8.attn.causal_mask', 'transformer.h.9.attn.causal_mask']\n",
            "- This IS expected if you are initializing CodeGenForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CodeGenForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model_name = \"Salesforce/codegen-350M-mono\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def generate_text(prompt, max_length=2000, num_return_sequences=1):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=num_return_sequences,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs][0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms.base import LLM\n",
        "from typing import Any\n",
        "\n",
        "class CustomHFLLM(LLM):\n",
        "    def _call(self, prompt: str, stop: Any = None) -> str:\n",
        "        return generate_text(prompt, max_length=500)\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"custom_huggingface\"\n",
        "\n",
        "llm = CustomHFLLM()"
      ],
      "metadata": {
        "id": "lUr1foDUKi2y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from langchain.schema import Document  # import Document\n",
        "dataset = load_dataset(\"openai/openai_humaneval\", split=\"test\")\n",
        "\n",
        "# convert to list of dicts\n",
        "dataset = list(dataset)\n",
        "documents = []\n",
        "\n",
        "for item in dataset:\n",
        "    doc_text = f\"Problem:\\n{item['prompt']}\\n\\nSolution:\\n{item.get('canonical_solution', 'Not available')}\"\n",
        "    metadata = {\"task_id\": item.get(\"task_id\", \"unknown\")}\n",
        "    documents.append(Document(page_content=doc_text, metadata=metadata))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "460c71379a3f4f05a005c8ff87dcfcae",
            "a057c1f742d1400abf34c71ed6be662e",
            "34a851ac9ec44948b91b3bed27f02240",
            "2e7025bc489d4fcca51cf7d51c5f1644",
            "d97594733ab44ae4b3064aba661e3e19",
            "2ba1faad5dcb4e9da4b4add4fd61af2e",
            "9397ee3657ee414b8c9e2f9fb34dd308",
            "553edd83e0cd4b7a88ca26a31e8baa3b",
            "421142aa627043febfe8cdfeb17ee70e",
            "1300e547e6004074925fa198e9b33398",
            "776f52dff4e04b27a2689206ac4f9206",
            "9aa06ef434684800be06099b13f024ed",
            "7bb15393766147a29d3ea8043ceb99d2",
            "fa6bcede46c84149a48048e8cec506db",
            "5376fdccd754479b9a3c5eb4b7a39404",
            "3e39b335fbd84d05b46b7ebc15383eea",
            "eafcc322eaac44ecafaad71b5844715f",
            "3e1a80a1d5674501b260f5c21b6cfcf4",
            "3e9d7db1ce03402ea662cae70c71b120",
            "278ecd82c3da450a872fda47d3f87ba3",
            "1c638099403644129e52c63690348c94",
            "2aebf1e1e2454d3486462b7bb5bdb576",
            "75741772809345d2b418330f5d51d094",
            "a04d69e31d2f4d81bb18b4a9bd203fa8",
            "61fc8b67071f4ceabac8e96de6f237a3",
            "f6181f9756994eaf885da33fb4203ec6",
            "5cb2863fdd744cf8b12dd5c5eba5d955",
            "ec3b01d4ec61409a9b9c0c043f396fb5",
            "0ac3feb7889a41cca4220c828d73c299",
            "6c16bb6a583a4496bf9acd9574590553",
            "76f11bdeda7840dfaa8eeb04196d79ac",
            "81ad769829c046b6a1932ec11f48ceb3",
            "04655bb193fd4a229c4d94f4ec7709e2"
          ]
        },
        "id": "_cr5yX-uKt76",
        "outputId": "46b14c1c-e188-4e92-af26-6c5ccf941e48"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "460c71379a3f4f05a005c8ff87dcfcae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "openai_humaneval/test-00000-of-00001.par(…):   0%|          | 0.00/83.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9aa06ef434684800be06099b13f024ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/164 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75741772809345d2b418330f5d51d094"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task0"
      ],
      "metadata": {
        "id": "UivAf9cH4uQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"You are a precise code comparison assistant. \"\n",
        "     \"Given a user's request and a retrieved code snippet from the HumanEval dataset, \"\n",
        "     \"determine if they achieve the same purpose. \"\n",
        "     \"If they match, return only the Python function from the retrieved code. \"\n",
        "     \"If they differ, ignore the retrieved code and generate a new Python function that fulfills the user's request. \"\n",
        "     \"Always return only the function, with no explanations or extra text.\"),\n",
        "    (\"user\",\n",
        "     \"User request: {user_request}\\n\\nRetrieved code snippet:\\n{retrieved_code}\")\n",
        "])\n",
        "\n",
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "CRCZutwnK1lb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task1"
      ],
      "metadata": {
        "id": "0pT1dWJ14rJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ChatMessageHistory\n",
        "from langchain_core.runnables import RunnableWithMessageHistory\n",
        "\n",
        "\n",
        "sessions = {}\n",
        "\n",
        "def get_history(session_id: str):\n",
        "    \"\"\"Fetch or create chat history for a session.\"\"\"\n",
        "    if session_id not in sessions:\n",
        "        sessions[session_id] = ChatMessageHistory()\n",
        "    return sessions[session_id]\n",
        "\n",
        "chat_with_memory = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_history,\n",
        "    input_messages_key=\"user_request\",\n",
        "    history_messages_key=\"history\"\n",
        ")\n",
        "\n",
        "\n",
        "def chat(user_request: str, retrieved_code: str = \"\", session_id: str = \"default\"):\n",
        "    \"\"\"Send request to LLM chain with session memory.\"\"\"\n",
        "    config = {\"configurable\": {\"session_id\": session_id}}\n",
        "    response = chat_with_memory.invoke(\n",
        "        {\"user_request\": user_request, \"retrieved_code\": retrieved_code},\n",
        "        config=config,\n",
        "        callbacks=[]\n",
        "    )\n",
        "    return response\n",
        "\n",
        "\n",
        "output = chat(\n",
        "    \"I want a function that returns 'Hello'\",\n",
        "    retrieved_code=\"def greet(): print('Hello!')\",\n",
        "    session_id=\"session1\"\n",
        ")\n",
        "print(\"LLM output:\\n\", output)\n",
        "\n",
        "history = get_history(\"session1\")\n",
        "print(\"\\nSession memory messages:\")\n",
        "for i, msg in enumerate(history.messages):\n",
        "    print(f\"{i+1}. {msg.type}: {msg.content}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7irjz9n5K8xU",
        "outputId": "7f80e5f6-9ec9-4945-b153-a449f7bba203"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM output:\n",
            " System: You are a precise code comparison assistant. Given a user's request and a retrieved code snippet from the HumanEval dataset, determine if they achieve the same purpose. If they match, return only the Python function from the retrieved code. If they differ, ignore the retrieved code and generate a new Python function that fulfills the user's request. Always return only the function, with no explanations or extra text.\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Retrieved code snippet:\n",
            "def greet(): print('Hello!')\n",
            "greet()\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function '\n",
            "\n",
            "Session memory messages:\n",
            "1. human: I want a function that returns 'Hello'\n",
            "2. ai: System: You are a precise code comparison assistant. Given a user's request and a retrieved code snippet from the HumanEval dataset, determine if they achieve the same purpose. If they match, return only the Python function from the retrieved code. If they differ, ignore the retrieved code and generate a new Python function that fulfills the user's request. Always return only the function, with no explanations or extra text.\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Retrieved code snippet:\n",
            "def greet(): print('Hello!')\n",
            "greet()\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function 'greet' with only one argument\n",
            "\n",
            "Human: User request: I want a function that returns 'Hello'\n",
            "\n",
            "Human: The function above returns the Python function '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2"
      ],
      "metadata": {
        "id": "WVE-iRAU4cGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "persist_directory = 'docs/chroma/'\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "\n",
        "    )\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"example_collection\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"./chroma_langchain_db\",\n",
        ")"
      ],
      "metadata": {
        "id": "zykl7iROLB3i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.add_documents(documents, ids=[str(i) for i in range(len(documents))])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLJq4o3FLJjK",
        "outputId": "068d9f7f-d300-436f-e826-810304ca784a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " '10',\n",
              " '11',\n",
              " '12',\n",
              " '13',\n",
              " '14',\n",
              " '15',\n",
              " '16',\n",
              " '17',\n",
              " '18',\n",
              " '19',\n",
              " '20',\n",
              " '21',\n",
              " '22',\n",
              " '23',\n",
              " '24',\n",
              " '25',\n",
              " '26',\n",
              " '27',\n",
              " '28',\n",
              " '29',\n",
              " '30',\n",
              " '31',\n",
              " '32',\n",
              " '33',\n",
              " '34',\n",
              " '35',\n",
              " '36',\n",
              " '37',\n",
              " '38',\n",
              " '39',\n",
              " '40',\n",
              " '41',\n",
              " '42',\n",
              " '43',\n",
              " '44',\n",
              " '45',\n",
              " '46',\n",
              " '47',\n",
              " '48',\n",
              " '49',\n",
              " '50',\n",
              " '51',\n",
              " '52',\n",
              " '53',\n",
              " '54',\n",
              " '55',\n",
              " '56',\n",
              " '57',\n",
              " '58',\n",
              " '59',\n",
              " '60',\n",
              " '61',\n",
              " '62',\n",
              " '63',\n",
              " '64',\n",
              " '65',\n",
              " '66',\n",
              " '67',\n",
              " '68',\n",
              " '69',\n",
              " '70',\n",
              " '71',\n",
              " '72',\n",
              " '73',\n",
              " '74',\n",
              " '75',\n",
              " '76',\n",
              " '77',\n",
              " '78',\n",
              " '79',\n",
              " '80',\n",
              " '81',\n",
              " '82',\n",
              " '83',\n",
              " '84',\n",
              " '85',\n",
              " '86',\n",
              " '87',\n",
              " '88',\n",
              " '89',\n",
              " '90',\n",
              " '91',\n",
              " '92',\n",
              " '93',\n",
              " '94',\n",
              " '95',\n",
              " '96',\n",
              " '97',\n",
              " '98',\n",
              " '99',\n",
              " '100',\n",
              " '101',\n",
              " '102',\n",
              " '103',\n",
              " '104',\n",
              " '105',\n",
              " '106',\n",
              " '107',\n",
              " '108',\n",
              " '109',\n",
              " '110',\n",
              " '111',\n",
              " '112',\n",
              " '113',\n",
              " '114',\n",
              " '115',\n",
              " '116',\n",
              " '117',\n",
              " '118',\n",
              " '119',\n",
              " '120',\n",
              " '121',\n",
              " '122',\n",
              " '123',\n",
              " '124',\n",
              " '125',\n",
              " '126',\n",
              " '127',\n",
              " '128',\n",
              " '129',\n",
              " '130',\n",
              " '131',\n",
              " '132',\n",
              " '133',\n",
              " '134',\n",
              " '135',\n",
              " '136',\n",
              " '137',\n",
              " '138',\n",
              " '139',\n",
              " '140',\n",
              " '141',\n",
              " '142',\n",
              " '143',\n",
              " '144',\n",
              " '145',\n",
              " '146',\n",
              " '147',\n",
              " '148',\n",
              " '149',\n",
              " '150',\n",
              " '151',\n",
              " '152',\n",
              " '153',\n",
              " '154',\n",
              " '155',\n",
              " '156',\n",
              " '157',\n",
              " '158',\n",
              " '159',\n",
              " '160',\n",
              " '161',\n",
              " '162',\n",
              " '163']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Write a function that calculate the factorial of mumber\"\n",
        "results = vector_store.similarity_search(query, k=1)\n",
        "top_doc = results[0]\n",
        "print(\"Page content:\\n\", top_doc.page_content)\n",
        "print(\"\\nMetadata:\\n\", top_doc.metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3U7UMS_LdDc",
        "outputId": "c2775813-575f-4ded-b2c8-e5383b80fbc4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page content:\n",
            " Problem:\n",
            "\n",
            "def special_factorial(n):\n",
            "    \"\"\"The Brazilian factorial is defined as:\n",
            "    brazilian_factorial(n) = n! * (n-1)! * (n-2)! * ... * 1!\n",
            "    where n > 0\n",
            "\n",
            "    For example:\n",
            "    >>> special_factorial(4)\n",
            "    288\n",
            "\n",
            "    The function will receive an integer as input and should return the special\n",
            "    factorial of this integer.\n",
            "    \"\"\"\n",
            "\n",
            "\n",
            "Solution:\n",
            "    fact_i = 1\n",
            "    special_fact = 1\n",
            "    for i in range(1, n+1):\n",
            "        fact_i *= i\n",
            "        special_fact *= fact_i\n",
            "    return special_fact\n",
            "\n",
            "\n",
            "Metadata:\n",
            " {'task_id': 'HumanEval/139'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(user_request, session_id=\"session-zero\"):\n",
        "\n",
        "    similar_docs =vector_store.similarity_search(user_request, k=1)\n",
        "    retrieved_code = similar_docs[0].page_content if similar_docs else \"\"\n",
        "\n",
        "\n",
        "    response = chat(user_request, retrieved_code=retrieved_code, session_id=session_id)\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "user_input = \"Write a Python function that checks if a number is prime\"\n",
        "generated_code = ask(user_input)\n",
        "\n",
        "print(\"=== Generated / Retrieved Code ===\")\n",
        "print(generated_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv9Bvc-sL9B5",
        "outputId": "9184c1d1-b6e3-4369-a83e-5caf79c2c5a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generated / Retrieved Code ===\n",
            "System: You are a precise code comparison assistant. Given a user's request and a retrieved code snippet from the HumanEval dataset, determine if they achieve the same purpose. If they match, return only the Python function from the retrieved code. If they differ, ignore the retrieved code and generate a new Python function that fulfills the user's request. Always return only the function, with no explanations or extra text.\n",
            "Human: User request: Write a Python function that checks if a number is prime\n",
            "\n",
            "Retrieved code snippet:\n",
            "Problem:\n",
            "\n",
            "\n",
            "def is_prime(n):\n",
            "    \"\"\"Return true if a given number is prime, and false otherwise.\n",
            "    >>> is_prime(6)\n",
            "    False\n",
            "    >>> is_prime(101)\n",
            "    True\n",
            "    >>> is_prime(11)\n",
            "    True\n",
            "    >>> is_prime(13441)\n",
            "    True\n",
            "    >>> is_prime(61)\n",
            "    True\n",
            "    >>> is_prime(4)\n",
            "    False\n",
            "    >>> is_prime(1)\n",
            "    False\n",
            "    \"\"\"\n",
            "\n",
            "\n",
            "Solution:\n",
            "    if n < 2:\n",
            "        return False\n",
            "    for k in range(2, n - 1):\n",
            "        if n % k == 0:\n",
            "            return False\n",
            "    return True\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3"
      ],
      "metadata": {
        "id": "aj3tKtBK4Uia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_precision_at_k(retrieved_docs, relevant_docs, k):\n",
        "    \"\"\"Calculate Precision@K - proportion of retrieved docs that are relevant\"\"\"\n",
        "    if k == 0 or not retrieved_docs:\n",
        "        return 0.0\n",
        "\n",
        "    retrieved_k = retrieved_docs[:k]\n",
        "    relevant_ids = {doc.metadata.get('task_id', '') for doc in relevant_docs}\n",
        "\n",
        "    relevant_count = 0\n",
        "    for doc in retrieved_k:\n",
        "        if doc.metadata.get('task_id', '') in relevant_ids:\n",
        "            relevant_count += 1\n",
        "\n",
        "    return relevant_count / k\n",
        "\n",
        "def calculate_recall_at_k(retrieved_docs, relevant_docs, k):\n",
        "    \"\"\"Calculate Recall@K - proportion of relevant docs that are retrieved\"\"\"\n",
        "    if not relevant_docs:\n",
        "        return 0.0\n",
        "\n",
        "    retrieved_k = retrieved_docs[:k]\n",
        "    relevant_ids = {doc.metadata.get('task_id', '') for doc in relevant_docs}\n",
        "    retrieved_ids = {doc.metadata.get('task_id', '') for doc in retrieved_k}\n",
        "\n",
        "    relevant_retrieved = len(relevant_ids.intersection(retrieved_ids))\n",
        "    return relevant_retrieved / len(relevant_ids)\n",
        "\n",
        "def calculate_mrr(retrieved_docs, relevant_docs):\n",
        "    \"\"\"Calculate Mean Reciprocal Rank - reciprocal of rank of first relevant doc\"\"\"\n",
        "    if not relevant_docs:\n",
        "        return 0.0\n",
        "\n",
        "    relevant_ids = {doc.metadata.get('task_id', '') for doc in relevant_docs}\n",
        "\n",
        "    for rank, doc in enumerate(retrieved_docs, 1):\n",
        "        if doc.metadata.get('task_id', '') in relevant_ids:\n",
        "            return 1.0 / rank\n",
        "\n",
        "    return 0.0\n",
        "\n",
        "def calculate_ndcg_at_k(retrieved_docs, relevant_docs, k):\n",
        "    \"\"\"Calculate nDCG@K - measures ranking quality\"\"\"\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Binary relevance\n",
        "    relevance_scores = []\n",
        "    relevant_ids = {doc.metadata.get('task_id', '') for doc in relevant_docs}\n",
        "\n",
        "    for doc in retrieved_docs[:k]:\n",
        "        if doc.metadata.get('task_id', '') in relevant_ids:\n",
        "            relevance_scores.append(1)\n",
        "        else:\n",
        "            relevance_scores.append(0)\n",
        "\n",
        "    # Calculate DCG\n",
        "    dcg = 0.0\n",
        "    for i, rel in enumerate(relevance_scores):\n",
        "        dcg += rel / np.log2(i + 2)\n",
        "\n",
        "    # Calculate ideal DCG\n",
        "    ideal_relevance = [1] * min(len(relevant_docs), k)\n",
        "    ideal_dcg = 0.0\n",
        "    for i, rel in enumerate(ideal_relevance):\n",
        "        ideal_dcg += rel / np.log2(i + 2)\n",
        "\n",
        "    return dcg / ideal_dcg if ideal_dcg > 0 else 0.0\n",
        "\n",
        "def evaluate_retrieval(query, ground_truth_docs, k_values=[1, 3, 5]):\n",
        "    \"\"\"Comprehensive retrieval evaluation for a query\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=max(k_values))\n",
        "\n",
        "    results = {}\n",
        "    for k in k_values:\n",
        "        results[f'precision@{k}'] = calculate_precision_at_k(retrieved_docs, ground_truth_docs, k)\n",
        "        results[f'recall@{k}'] = calculate_recall_at_k(retrieved_docs, ground_truth_docs, k)\n",
        "        results[f'ndcg@{k}'] = calculate_ndcg_at_k(retrieved_docs, ground_truth_docs, k)\n",
        "\n",
        "    results['mrr'] = calculate_mrr(retrieved_docs, ground_truth_docs)\n",
        "\n",
        "    return results, retrieved_docs\n",
        "\n"
      ],
      "metadata": {
        "id": "b871mSvPD8t7"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task4"
      ],
      "metadata": {
        "id": "RbOcvRpbGaeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def evaluate_with_deepeval(query, generated_answer, retrieved_docs, ground_truth=None):\n",
        "    \"\"\"Single function for DeepEval evaluation - Task 4\"\"\"\n",
        "    try:\n",
        "        from deepeval.metrics import AnswerRelevancyMetric, ContextualPrecisionMetric, ContextualRecallMetric\n",
        "        from deepeval.test_case import LLMTestCase\n",
        "\n",
        "        # Convert documents to context\n",
        "        context = [doc.page_content for doc in retrieved_docs]\n",
        "\n",
        "        # Create test case\n",
        "        test_case = LLMTestCase(\n",
        "            input=query,\n",
        "            actual_output=generated_answer,\n",
        "            expected_output=ground_truth or generated_answer,\n",
        "            context=context,\n",
        "            retrieval_context=context\n",
        "        )\n",
        "\n",
        "        # Initialize and compute metrics\n",
        "        answer_relevancy = AnswerRelevancyMetric(threshold=0.7)\n",
        "        contextual_precision = ContextualPrecisionMetric(threshold=0.7)\n",
        "        contextual_recall = ContextualRecallMetric(threshold=0.7)\n",
        "\n",
        "        answer_relevancy.measure(test_case)\n",
        "        contextual_precision.measure(test_case)\n",
        "        contextual_recall.measure(test_case)\n",
        "\n",
        "        return {\n",
        "            'answer_relevancy': answer_relevancy.score,\n",
        "            'contextual_precision': contextual_precision.score,\n",
        "            'contextual_recall': contextual_recall.score,\n",
        "            'all_passed': (answer_relevancy.score >= 0.7 and\n",
        "                          contextual_precision.score >= 0.7 and\n",
        "                          contextual_recall.score >= 0.7)\n",
        "        }\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"DeepEval not installed. Install with: pip install deepeval\")\n",
        "        return {}"
      ],
      "metadata": {
        "id": "2aypIcIwFW76"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating some example documents to test the functions\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Use real data from your vector store\n",
        "print(\"=== USING REAL VECTOR STORE DATA ===\")\n",
        "\n",
        "# Test with actual queries against your vector store\n",
        "test_queries = [\n",
        "    \"Write a Python function that checks if a number is prime\",\n",
        "    \"Create a function to calculate factorial\",\n",
        "    \"Write a function to reverse a string\",\n",
        "    \"Write a function to find the maximum number in a list\"\n",
        "]\n",
        "\n",
        "ground_truth_docs = documents[:3]\n",
        "\n",
        "print(f\"Using {len(ground_truth_docs)} documents as ground truth\")\n",
        "print(f\"Vector store has {len(documents)} total documents\")\n",
        "\n",
        "for i, query in enumerate(test_queries, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"QUERY {i}: {query}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Get real retrieved documents from your vector store\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=5)\n",
        "    print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
        "\n",
        "    # Calculate Task 3 metrics with real data\n",
        "    precision_3 = calculate_precision_at_k(retrieved_docs, ground_truth_docs, 3)\n",
        "    recall_3 = calculate_recall_at_k(retrieved_docs, ground_truth_docs, 3)\n",
        "    mrr_score = calculate_mrr(retrieved_docs, ground_truth_docs)\n",
        "    ndcg_3 = calculate_ndcg_at_k(retrieved_docs, ground_truth_docs, 3)\n",
        "\n",
        "    print(\"TASK 3 - Retrieval Metrics:\")\n",
        "    print(f\"  Precision@3: {precision_3:.3f}\")\n",
        "    print(f\"  Recall@3: {recall_3:.3f}\")\n",
        "    print(f\"  MRR: {mrr_score:.3f}\")\n",
        "    print(f\"  nDCG@3: {ndcg_3:.3f}\")\n",
        "\n",
        "    # Show what was actually retrieved\n",
        "    print(\"\\nTop 3 retrieved documents:\")\n",
        "    for j, doc in enumerate(retrieved_docs[:3], 1):\n",
        "        print(f\"  {j}. {doc.page_content[:100]}...\")\n",
        "        print(f\"     Metadata: {doc.metadata}\")\n",
        "\n",
        "    # Test Task 4 with real generated answer\n",
        "    print(\"\\nTASK 4 - Generation Quality:\")\n",
        "\n",
        "    # Get real generated answer from your RAG system\n",
        "    generated_answer = ask(query, session_id=f\"test_{i}\")\n",
        "\n",
        "    print(\"Generated code:\")\n",
        "    print(generated_answer[:200] + \"...\" if len(generated_answer) > 200 else generated_answer)\n",
        "\n",
        "    # Try DeepEval evaluation\n",
        "    try:\n",
        "        deepeval_results = evaluate_with_deepeval(query, generated_answer, retrieved_docs[:3])\n",
        "        if deepeval_results:\n",
        "            print(\"DeepEval Metrics:\")\n",
        "            for metric, value in deepeval_results.items():\n",
        "                if metric != 'all_passed':\n",
        "                    print(f\"  {metric}: {value:.3f}\")\n",
        "            print(f\"  All tests passed: {deepeval_results['all_passed']}\")\n",
        "        else:\n",
        "            print(\"  DeepEval: Not available (install and set API key)\")\n",
        "    except Exception as e:\n",
        "        print(f\"  DeepEval Error: {str(e)[:100]}...\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"REAL DATA EVALUATION COMPLETED!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Also test the comprehensive evaluation function with real data\n",
        "print(\"\\n=== COMPREHENSIVE EVALUATION WITH REAL DATA ===\")\n",
        "sample_query = \"Write a function that calculates factorial\"\n",
        "print(f\"Testing comprehensive evaluation with: '{sample_query}'\")\n",
        "\n",
        "comprehensive_results, real_retrieved_docs = evaluate_retrieval(sample_query, ground_truth_docs)\n",
        "print(\"Comprehensive Results:\")\n",
        "for metric, value in comprehensive_results.items():\n",
        "    print(f\"  {metric}: {value:.3f}\")\n",
        "\n",
        "print(f\"\\nActually retrieved {len(real_retrieved_docs)} documents\")\n",
        "print(\"Sample of retrieved content:\")\n",
        "for i, doc in enumerate(real_retrieved_docs[:2], 1):\n",
        "    print(f\"  {i}. {doc.page_content[:150]}...\")"
      ],
      "metadata": {
        "id": "zfmKB3_mJePX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}